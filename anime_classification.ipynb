{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anime-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_r9WWAsUnME",
        "colab_type": "text"
      },
      "source": [
        "# Classifying 90+ Anime Characters with Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3q-Asqm6wBV",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqITqJpwo3qd",
        "colab_type": "text"
      },
      "source": [
        "First, install the prerequisite libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTdmmn3TJZIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import zipfile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vjawztquI4P",
        "colab_type": "text"
      },
      "source": [
        "Extract the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yScHl4c1qrPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/anime_dataset'\n",
        "\n",
        "with zipfile.ZipFile(\"/content/drive/My Drive/dataset_cropped.zip\") as datazip:\n",
        "  datazip.extractall(base_dir)\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'cropped_images', 'train')\n",
        "train_dir = os.path.join(base_dir, 'cropped_images', 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ovNz1Z8YM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/anime_dataset'\n",
        "train_dir = os.path.join(base_dir, 'cropped_images', 'train')\n",
        "validation_dir = os.path.join(base_dir, 'cropped_images', 'validation')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxyZRXh6vJMw",
        "colab_type": "text"
      },
      "source": [
        "Setup data augmentation/batch sizes for input:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcOV8wLKunyA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "567ecd4b-a4e6-4ed4-ebdf-ff7b3e031a5d"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input, # Preprocess images for ResNet50\n",
        "    rotation_range=30, # Randomly rotate the image up to 30 degrees\n",
        "    horizontal_flip=True # Randomly flip the image horizontally\n",
        ")\n",
        "\n",
        "# No need for data augmentation in validation\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    class_mode='categorical', # Since we're classifying many different classes \n",
        "    batch_size=32, # Flow in batches of 32 images\n",
        "    target_size=(244,244) # Reshape images to max image dimensions for ResNet50\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    target_size=(244,244)\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6341 images belonging to 94 classes.\n",
            "Found 1063 images belonging to 94 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy8tjB1N3D0b",
        "colab_type": "text"
      },
      "source": [
        "Import and configure the base model (Inception V3):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W8CVs3P3KZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "62f2abd4-39e3-4ada-e456-6d784235fdff"
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False, # Don't include last output layer for transfer learning\n",
        "    input_shape=(244,244,3),\n",
        "    weights='imagenet' # Import the weights for imagenet\n",
        ")\n",
        "\n",
        "base_model.trainable = False # Freeze the layers so we're not retraining"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXrPC4LZ6y5a",
        "colab_type": "text"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3dGx80S4f2m",
        "colab_type": "text"
      },
      "source": [
        "Create our own layers:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAMVNjEu4kId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pool the 3D output into a 2D feature vector to connect conv layers to our fully connected layers\n",
        "global_avg_layer = tf.keras.layers.GlobalAveragePooling2D() \n",
        "fc_layer = tf.keras.layers.Dense(1024, activation='relu')\n",
        "output_layer = tf.keras.layers.Dense(94, activation='softmax') # Since we have 94 classes"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nejr_TWR66ac",
        "colab_type": "text"
      },
      "source": [
        "Build our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcQurBSP68pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.Input(shape=(244,244,3))\n",
        "x = base_model(inputs, training=False) # We need training=False since we have batch normalization layers in ResNet50\n",
        "x = global_avg_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x) # For regularization\n",
        "# x = fc_layer(x)\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = output_layer(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swyhhrdk-DL6",
        "colab_type": "text"
      },
      "source": [
        "Compile our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PUPpvCP9_9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "5fb94c47-4837-4bfa-c156-20f82ff83411"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 244, 244, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, 8, 8, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 94)                192606    \n",
            "=================================================================\n",
            "Total params: 23,780,318\n",
            "Trainable params: 192,606\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twmCBJpi-llV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v96VmhUBOui",
        "colab_type": "text"
      },
      "source": [
        "Train the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuAoO6IuCC6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import PngImagePlugin\n",
        "import h5py\n",
        "\n",
        "LARGE_ENOUGH_NUMBER = 100\n",
        "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)\n",
        "\n",
        "chkpoint_fp = '/content/drive/My Drive/chkpoints/resnetmodel.h5'\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=chkpoint_fp,\n",
        "    monitor='val_accuracy',\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0_1Hzy3-Xtm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f49683a-dc55-4c77-da1c-377810eac30d"
      },
      "source": [
        "history = model.fit(\n",
        "    x=train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=100,\n",
        "    callbacks=[model_checkpoint],\n",
        "    steps_per_epoch=198 # Since we have 6341 training images and batch sizes of 32, after 198 batches we'll have gone through a little less than the whole training set\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "198/198 [==============================] - 165s 836ms/step - loss: 4.7432 - accuracy: 0.0274 - val_loss: 4.1996 - val_accuracy: 0.0677\n",
            "Epoch 2/100\n",
            "198/198 [==============================] - 169s 854ms/step - loss: 4.0896 - accuracy: 0.0802 - val_loss: 3.7186 - val_accuracy: 0.1543\n",
            "Epoch 3/100\n",
            "198/198 [==============================] - 169s 853ms/step - loss: 3.6284 - accuracy: 0.1667 - val_loss: 3.3513 - val_accuracy: 0.2408\n",
            "Epoch 4/100\n",
            "198/198 [==============================] - 168s 851ms/step - loss: 3.2486 - accuracy: 0.2360 - val_loss: 3.0751 - val_accuracy: 0.3029\n",
            "Epoch 5/100\n",
            "198/198 [==============================] - 167s 846ms/step - loss: 2.9621 - accuracy: 0.3010 - val_loss: 2.8511 - val_accuracy: 0.3603\n",
            "Epoch 6/100\n",
            "198/198 [==============================] - 168s 848ms/step - loss: 2.7435 - accuracy: 0.3484 - val_loss: 2.6830 - val_accuracy: 0.3932\n",
            "Epoch 7/100\n",
            "198/198 [==============================] - 168s 849ms/step - loss: 2.5459 - accuracy: 0.4083 - val_loss: 2.5393 - val_accuracy: 0.4327\n",
            "Epoch 8/100\n",
            "198/198 [==============================] - 169s 852ms/step - loss: 2.3955 - accuracy: 0.4302 - val_loss: 2.4110 - val_accuracy: 0.4450\n",
            "Epoch 9/100\n",
            "198/198 [==============================] - 168s 851ms/step - loss: 2.2527 - accuracy: 0.4614 - val_loss: 2.3133 - val_accuracy: 0.4638\n",
            "Epoch 10/100\n",
            "198/198 [==============================] - 167s 846ms/step - loss: 2.1458 - accuracy: 0.4871 - val_loss: 2.2353 - val_accuracy: 0.4666\n",
            "Epoch 11/100\n",
            "198/198 [==============================] - 169s 853ms/step - loss: 2.0321 - accuracy: 0.5128 - val_loss: 2.1668 - val_accuracy: 0.4939\n",
            "Epoch 12/100\n",
            "198/198 [==============================] - 168s 849ms/step - loss: 1.9582 - accuracy: 0.5362 - val_loss: 2.0883 - val_accuracy: 0.5080\n",
            "Epoch 13/100\n",
            "198/198 [==============================] - 167s 844ms/step - loss: 1.8699 - accuracy: 0.5522 - val_loss: 2.0337 - val_accuracy: 0.5212\n",
            "Epoch 14/100\n",
            "198/198 [==============================] - 163s 824ms/step - loss: 1.7863 - accuracy: 0.5765 - val_loss: 1.9724 - val_accuracy: 0.5212\n",
            "Epoch 15/100\n",
            "198/198 [==============================] - 167s 843ms/step - loss: 1.7254 - accuracy: 0.5833 - val_loss: 1.9291 - val_accuracy: 0.5259\n",
            "Epoch 16/100\n",
            "198/198 [==============================] - 166s 840ms/step - loss: 1.6805 - accuracy: 0.5909 - val_loss: 1.8816 - val_accuracy: 0.5437\n",
            "Epoch 17/100\n",
            "198/198 [==============================] - 168s 849ms/step - loss: 1.6046 - accuracy: 0.6102 - val_loss: 1.8512 - val_accuracy: 0.5503\n",
            "Epoch 18/100\n",
            "198/198 [==============================] - 167s 843ms/step - loss: 1.5612 - accuracy: 0.6145 - val_loss: 1.8235 - val_accuracy: 0.5513\n",
            "Epoch 19/100\n",
            "198/198 [==============================] - 167s 843ms/step - loss: 1.5040 - accuracy: 0.6345 - val_loss: 1.7950 - val_accuracy: 0.5626\n",
            "Epoch 20/100\n",
            "198/198 [==============================] - 167s 841ms/step - loss: 1.4761 - accuracy: 0.6434 - val_loss: 1.7488 - val_accuracy: 0.5710\n",
            "Epoch 21/100\n",
            "198/198 [==============================] - 166s 838ms/step - loss: 1.4233 - accuracy: 0.6575 - val_loss: 1.7362 - val_accuracy: 0.5748\n",
            "Epoch 22/100\n",
            "198/198 [==============================] - 162s 816ms/step - loss: 1.3913 - accuracy: 0.6518 - val_loss: 1.7065 - val_accuracy: 0.5691\n",
            "Epoch 23/100\n",
            "198/198 [==============================] - 165s 835ms/step - loss: 1.3681 - accuracy: 0.6595 - val_loss: 1.6877 - val_accuracy: 0.5757\n",
            "Epoch 24/100\n",
            "198/198 [==============================] - 160s 809ms/step - loss: 1.3248 - accuracy: 0.6732 - val_loss: 1.6688 - val_accuracy: 0.5757\n",
            "Epoch 25/100\n",
            "198/198 [==============================] - 164s 827ms/step - loss: 1.2822 - accuracy: 0.6822 - val_loss: 1.6462 - val_accuracy: 0.5898\n",
            "Epoch 26/100\n",
            "198/198 [==============================] - 164s 830ms/step - loss: 1.2588 - accuracy: 0.6871 - val_loss: 1.6354 - val_accuracy: 0.5908\n",
            "Epoch 27/100\n",
            "198/198 [==============================] - 163s 825ms/step - loss: 1.2269 - accuracy: 0.6988 - val_loss: 1.6054 - val_accuracy: 0.5983\n",
            "Epoch 28/100\n",
            "198/198 [==============================] - 160s 809ms/step - loss: 1.1897 - accuracy: 0.7047 - val_loss: 1.5939 - val_accuracy: 0.5908\n",
            "Epoch 29/100\n",
            "198/198 [==============================] - 167s 845ms/step - loss: 1.1676 - accuracy: 0.7196 - val_loss: 1.5808 - val_accuracy: 0.5992\n",
            "Epoch 30/100\n",
            "198/198 [==============================] - 168s 849ms/step - loss: 1.1455 - accuracy: 0.7185 - val_loss: 1.5610 - val_accuracy: 0.6171\n",
            "Epoch 31/100\n",
            "198/198 [==============================] - 163s 823ms/step - loss: 1.1229 - accuracy: 0.7218 - val_loss: 1.5475 - val_accuracy: 0.6162\n",
            "Epoch 32/100\n",
            "198/198 [==============================] - 163s 823ms/step - loss: 1.0852 - accuracy: 0.7321 - val_loss: 1.5319 - val_accuracy: 0.6171\n",
            "Epoch 33/100\n",
            "198/198 [==============================] - 167s 843ms/step - loss: 1.0837 - accuracy: 0.7291 - val_loss: 1.5307 - val_accuracy: 0.6256\n",
            "Epoch 34/100\n",
            "198/198 [==============================] - 163s 822ms/step - loss: 1.0477 - accuracy: 0.7421 - val_loss: 1.5142 - val_accuracy: 0.6256\n",
            "Epoch 35/100\n",
            "198/198 [==============================] - 165s 833ms/step - loss: 1.0249 - accuracy: 0.7486 - val_loss: 1.4998 - val_accuracy: 0.6209\n",
            "Epoch 36/100\n",
            "198/198 [==============================] - 169s 853ms/step - loss: 1.0064 - accuracy: 0.7538 - val_loss: 1.4931 - val_accuracy: 0.6275\n",
            "Epoch 37/100\n",
            "198/198 [==============================] - 169s 854ms/step - loss: 0.9914 - accuracy: 0.7540 - val_loss: 1.4754 - val_accuracy: 0.6312\n",
            "Epoch 38/100\n",
            "198/198 [==============================] - 169s 856ms/step - loss: 0.9733 - accuracy: 0.7670 - val_loss: 1.4777 - val_accuracy: 0.6350\n",
            "Epoch 39/100\n",
            "198/198 [==============================] - 171s 863ms/step - loss: 0.9520 - accuracy: 0.7641 - val_loss: 1.4591 - val_accuracy: 0.6416\n",
            "Epoch 40/100\n",
            "198/198 [==============================] - 162s 818ms/step - loss: 0.9480 - accuracy: 0.7621 - val_loss: 1.4630 - val_accuracy: 0.6397\n",
            "Epoch 41/100\n",
            "198/198 [==============================] - 164s 828ms/step - loss: 0.9346 - accuracy: 0.7740 - val_loss: 1.4394 - val_accuracy: 0.6397\n",
            "Epoch 42/100\n",
            "198/198 [==============================] - 167s 845ms/step - loss: 0.9047 - accuracy: 0.7816 - val_loss: 1.4383 - val_accuracy: 0.6444\n",
            "Epoch 43/100\n",
            "198/198 [==============================] - 164s 828ms/step - loss: 0.8981 - accuracy: 0.7813 - val_loss: 1.4417 - val_accuracy: 0.6350\n",
            "Epoch 44/100\n",
            "198/198 [==============================] - 163s 824ms/step - loss: 0.8879 - accuracy: 0.7840 - val_loss: 1.4281 - val_accuracy: 0.6406\n",
            "Epoch 45/100\n",
            "198/198 [==============================] - 164s 827ms/step - loss: 0.8616 - accuracy: 0.7893 - val_loss: 1.4182 - val_accuracy: 0.6416\n",
            "Epoch 46/100\n",
            "198/198 [==============================] - 161s 815ms/step - loss: 0.8544 - accuracy: 0.7930 - val_loss: 1.4067 - val_accuracy: 0.6444\n",
            "Epoch 47/100\n",
            "198/198 [==============================] - 160s 807ms/step - loss: 0.8396 - accuracy: 0.7954 - val_loss: 1.4015 - val_accuracy: 0.6378\n",
            "Epoch 48/100\n",
            "198/198 [==============================] - 165s 833ms/step - loss: 0.8336 - accuracy: 0.7955 - val_loss: 1.3990 - val_accuracy: 0.6491\n",
            "Epoch 49/100\n",
            "198/198 [==============================] - 163s 821ms/step - loss: 0.8128 - accuracy: 0.8027 - val_loss: 1.4056 - val_accuracy: 0.6444\n",
            "Epoch 50/100\n",
            "198/198 [==============================] - 162s 820ms/step - loss: 0.7978 - accuracy: 0.8036 - val_loss: 1.3996 - val_accuracy: 0.6416\n",
            "Epoch 51/100\n",
            "198/198 [==============================] - 163s 821ms/step - loss: 0.7889 - accuracy: 0.8138 - val_loss: 1.3911 - val_accuracy: 0.6378\n",
            "Epoch 52/100\n",
            "198/198 [==============================] - 162s 820ms/step - loss: 0.7950 - accuracy: 0.8031 - val_loss: 1.3656 - val_accuracy: 0.6482\n",
            "Epoch 53/100\n",
            "198/198 [==============================] - 163s 822ms/step - loss: 0.7701 - accuracy: 0.8125 - val_loss: 1.3748 - val_accuracy: 0.6453\n",
            "Epoch 54/100\n",
            "198/198 [==============================] - 166s 837ms/step - loss: 0.7490 - accuracy: 0.8182 - val_loss: 1.3673 - val_accuracy: 0.6510\n",
            "Epoch 55/100\n",
            "198/198 [==============================] - 162s 819ms/step - loss: 0.7393 - accuracy: 0.8202 - val_loss: 1.3737 - val_accuracy: 0.6472\n",
            "Epoch 56/100\n",
            " 14/198 [=>............................] - ETA: 2:09 - loss: 0.6456 - accuracy: 0.8594"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-6617006ca383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m198\u001b[0m \u001b[0;31m# Since we have 6341 training images and batch sizes of 32, after 198 batches we'll have gone through a little less than the whole training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQeZcPUNAp2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}